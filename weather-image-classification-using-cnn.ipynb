{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":4063112,"datasetId":2405622,"databundleVersionId":4119180}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" Note: This notebook is shared in a clean format (without cell outputs) for readability and version control.  \n The model was trained and evaluated separately, and the results are summarized in the README file.","metadata":{}},{"cell_type":"markdown","source":"## Weather Image Classification using Convolutional Neural Networks (CNN)\n\nThis project aims to classify weather conditions from images by building a Convolutional Neural Network (CNN) model.  \nFor this purpose, the Kaggle **5-Class Weather Status Image Classification** dataset is utilized for training and evaluation.","metadata":{}},{"cell_type":"markdown","source":"## Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install opencv-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Preparation and Splitting\n\nThe dataset is preprocessed and divided into training, validation, and test subsets to improve model generalization and enable reliable performance evaluation.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n\noriginal_dataset_dir = '/kaggle/input/5class-weather-status-image-classification/data'  \n\n# Yeni dataset klasörü (train/validation/test olacak)\nbase_dir = '/kaggle/working/dataset_split'  \nos.makedirs(base_dir, exist_ok=True)\n\n# Train/Validation/Test klasörlerini oluştur\nfor split in ['train', 'validation', 'test']:\n    split_dir = os.path.join(base_dir, split)\n    os.makedirs(split_dir, exist_ok=True)\n\n    for class_name in os.listdir(original_dataset_dir):\n        class_split_dir = os.path.join(split_dir, class_name)\n        os.makedirs(class_split_dir, exist_ok=True)\n\n        class_dir = os.path.join(original_dataset_dir, class_name)\n        images = os.listdir(class_dir)\n        random.shuffle(images)\n\n        # %70 train, %20 validation, %10 test\n        train_split = int(0.7 * len(images))\n        val_split = int(0.9 * len(images))\n\n        train_images = images[:train_split]\n        val_images = images[train_split:val_split]\n        test_images = images[val_split:]\n\n        # Dosyaları kopyala\n        for img in train_images:\n            shutil.copy(os.path.join(class_dir, img), os.path.join(split_dir, class_name, img))\n        for img in val_images:\n            shutil.copy(os.path.join(class_dir, img), os.path.join(split_dir, class_name, img))\n        for img in test_images:\n            shutil.copy(os.path.join(class_dir, img), os.path.join(split_dir, class_name, img))\n\nprint(\"Dataset train/validation/test olarak ayrıldı!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preprocessing and Visualization\n\nThe dataset is normalized to the [0, 1] range.  \nClass labels are defined, and sample images are visualized to better understand the data distribution.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os \nimport numpy as np \n\n# 1. ImageDataGenerator Tanımlamaları \ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,           \n    width_shift_range=0.25,      \n    height_shift_range=0.25,     \n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\n#  2. Data Generator Akışları\ntrain_generator = train_datagen.flow_from_directory(\n    os.path.join(base_dir, 'train'),\n    target_size=(64, 64),\n    batch_size=128,\n    class_mode='categorical',\n    shuffle=True\n)\n\nvalidation_generator = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir, 'validation'),\n    target_size=(64, 64),\n    batch_size=128,\n    class_mode='categorical',\n    shuffle=False \n)\n\ntest_generator = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir, 'test'),\n    target_size=(64, 64),\n    batch_size=128,\n    class_mode='categorical',\n    shuffle=False\n)\n\nprint(f\"\\nEğitim verisi: {train_generator.n} resim\")\nprint(f\"Doğrulama verisi: {validation_generator.n} resim\")\nprint(f\"Test verisi: {test_generator.n} resim\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T15:44:52.476826Z","iopub.execute_input":"2025-09-25T15:44:52.477277Z","iopub.status.idle":"2025-09-25T15:44:53.068573Z","shell.execute_reply.started":"2025-09-25T15:44:52.477258Z","shell.execute_reply":"2025-09-25T15:44:53.067758Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Building the Neural Network (CNN Architecture)\n\nThe model is constructed using `tf.keras.Sequential()`.  \nThe architecture consists of the following layers:\n\n- Conv2D (Convolutional Layers) for feature extraction  \n- MaxPooling2D (Pooling Layers) for spatial downsampling  \n- Flatten layer for vectorization  \n- Dense (Fully Connected Layers) for classification  \n- Dropout layer for regularization and overfitting prevention","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Model, Input, layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau # Dinamik hız kontrolü için eklendi\n\ninputs = Input(shape=(64, 64, 3))\n\n# BLOK 1\nx = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs) \nx = layers.MaxPooling2D(2,2)(x)\n\n\n# BLOK 2\nx = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x) \nx = layers.MaxPooling2D(2,2)(x)\nx = layers.Dropout(0.25)(x) \n\n# BLOK 3\nx = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x) \nx = layers.MaxPooling2D(2,2)(x)\nx = layers.Dropout(0.25)(x)\n\n# BLOK 4\nx = layers.Conv2D(512, (3,3), activation='relu', padding='same')(x) \nx = layers.MaxPooling2D(2,2)(x)\n\nx = layers.Flatten()(x)\n\n# TAM BAĞLANTILI KATMANLAR\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.4)(x) \n\noutputs = layers.Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\n# Öğrenme hızı 0.0005 olarak ayarlandı\noptimizer = Adam(learning_rate=0.0005) \n\nmodel.compile(\n    optimizer=optimizer, \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:51:39.615959Z","iopub.execute_input":"2025-09-25T18:51:39.616259Z","iopub.status.idle":"2025-09-25T18:51:39.681627Z","shell.execute_reply.started":"2025-09-25T18:51:39.616237Z","shell.execute_reply":"2025-09-25T18:51:39.681147Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training\n\nThe model is trained using the `model.fit()` method.  \nAfter the training process, the trained model is saved using `model.save()` for future use and reproducibility.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Callbacks tanımlamaları\nearly_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10) \n\n# Eğitimi başlat\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=100, # Veya daha fazla\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[early_stopping, reduce_lr] \n)\nmodel.save('final_best_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:51:44.465795Z","iopub.execute_input":"2025-09-25T18:51:44.466039Z","iopub.status.idle":"2025-09-25T19:58:50.589322Z","shell.execute_reply.started":"2025-09-25T18:51:44.466024Z","shell.execute_reply":"2025-09-25T19:58:50.588741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization of Training Results and Accuracy\n\nTraining and validation results are visualized using graphical plots to analyze the learning process.  \nModel accuracy is calculated to evaluate the overall performance during training.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Eğitim Doğruluğu')\nplt.plot(epochs_range, val_acc, label='Doğrulama Doğruluğu')\nplt.legend(loc='lower right')\nplt.title('Eğitim ve Doğrulama Doğruluğu')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Eğitim Kaybı')\nplt.plot(epochs_range, val_loss, label='Doğrulama Kaybı')\nplt.legend(loc='upper right')\nplt.title('Eğitim ve Doğrulama Kaybı')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T20:00:29.269157Z","iopub.execute_input":"2025-09-25T20:00:29.269497Z","iopub.status.idle":"2025-09-25T20:00:29.568700Z","shell.execute_reply.started":"2025-09-25T20:00:29.269460Z","shell.execute_reply":"2025-09-25T20:00:29.567917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Performance Evaluation\n\nThe model’s performance is evaluated on the test dataset using appropriate evaluation metrics to assess its generalization capability.","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(\n    test_generator,\n    steps=len(test_generator),\n    verbose=2\n)\n\nprint(f\"Test kaybı: {test_loss:.4f}\")\nprint(f\"Test doğruluk: {test_acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T20:00:36.169070Z","iopub.execute_input":"2025-09-25T20:00:36.169764Z","iopub.status.idle":"2025-09-25T20:00:55.184606Z","shell.execute_reply.started":"2025-09-25T20:00:36.169734Z","shell.execute_reply":"2025-09-25T20:00:55.183815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction and Inference\n\nPredictions are generated using the `model.predict()` method on unseen sample images to test the model’s classification capability.","metadata":{}},{"cell_type":"code","source":"\nsample_batch, _ = next(test_generator)\nsample_image = sample_batch[0:1]  \n\n# Tahmin yap\npred = model.predict(sample_image)  # output: [[0.1, 0.2, 0.05, 0.6, 0.05]]\n\n# Tahmin edilen sınıf\npredicted_class_index = np.argmax(pred, axis=1)[0]\n\n# Tahmin olasılığı\npredicted_prob = np.max(pred)\n\n# Sınıf isimleri\nclass_names = ['cloudy', 'foggy', 'rainy', 'snowy', 'sunny']\npredicted_class_name = class_names[predicted_class_index]\n\nprint(f\"Modelin tahmini sınıfı: {predicted_class_name}\")\nprint(f\"Tahmin olasılığı: {predicted_prob*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T20:01:01.921876Z","iopub.execute_input":"2025-09-25T20:01:01.922147Z","iopub.status.idle":"2025-09-25T20:01:02.980377Z","shell.execute_reply.started":"2025-09-25T20:01:01.922127Z","shell.execute_reply":"2025-09-25T20:01:02.979679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Interpretability with Grad-CAM\n\nGrad-CAM (Gradient-weighted Class Activation Mapping) is used to visualize the regions of the input images that the model focuses on during classification.  \nThis technique helps interpret the model’s decision-making process by highlighting the most influential areas in the image.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras import layers, Model, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n\ntry:\n    # Model, eğitimden sonra kaydedilen dosyadan yükleniyor.\n    model = tf.keras.models.load_model('final_best_model.h5')\n    # Son katman adını model yüklendikten sonra alıyoruz\n    LAST_CONV_LAYER_NAME = None\n    for layer in reversed(model.layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            LAST_CONV_LAYER_NAME = layer.name\n            break\n    print(\"✅ Model, kaydedilen ağırlıklarla başarıyla yüklendi.\")\n    print(\"Grad-CAM için kullanılacak katman:\", LAST_CONV_LAYER_NAME)\n\nexcept Exception as e:\n    # Yükleme başarısız olursa, Grad-CAM çalışmaz.\n    print(\"❌ Kayıtlı model yüklenemedi. Lütfen önce 'Run All' ile modeli eğitin ve kaydedin.\")\n    print(f\"Hata: {e}\")\n    # Eğer yüklenemezse, kodun geri kalanının çalışmasını durdururuz\n    raise SystemExit(0) \n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    img_array = tf.convert_to_tensor(img_array, dtype=tf.float32)\n    grad_model = Model(\n        [model.input], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n    grads = tape.gradient(class_channel, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n# Heatmap Görselleştirme \n\ndef display_gradcam(img_array, heatmap, title=\"Grad-CAM\"):\n    img = np.uint8(255 * img_array) if img_array.max() <= 1 else np.uint8(img_array)\n    heatmap = cv2.resize(heatmap, (int(img.shape[1]), int(img.shape[0])), interpolation=cv2.INTER_LINEAR)\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n    \n    # Görseli göster\n    plt.figure(figsize=(6, 4))\n    plt.imshow(superimposed_img)\n    plt.title(title)\n    plt.axis('off')\n    plt.show()\n\n\nCLASS_NAMES = ['cloudy', 'foggy', 'rainy', 'snowy', 'sunny']\n\n\n# Grad-CAM Uygulaması (Rastgele 15 Tahmin)\n\nprint(\"\\n--- Grad-CAM ile Model Yorumlanabilirliği (Rastgele Tahminler) ---\")\n\niterator = iter(test_generator) \n\n\nfor batch_num in range(5): \n    try:\n        images, labels = next(iterator)\n    except StopIteration:\n        break\n\n    print(f\"\\n--- Batch {batch_num + 1} İşleniyor ---\")\n    \n    for i in range(min(len(images), 3)): \n        img_array = images[i]\n        true_index = tf.argmax(labels[i]).numpy()\n        true_label = CLASS_NAMES[true_index]\n        \n        img_for_pred = tf.expand_dims(img_array, axis=0)\n        img_for_pred = tf.convert_to_tensor(img_for_pred, dtype=tf.float32)\n        \n        # Tahmin \n        predictions = model.predict(img_for_pred, verbose=0)\n        predicted_index = np.argmax(predictions[0])\n        predicted_label = CLASS_NAMES[predicted_index]\n\n        # Grad-CAM'i çalıştır \n        heatmap = make_gradcam_heatmap(\n            img_for_pred, model, LAST_CONV_LAYER_NAME, pred_index=predicted_index\n        )\n        \n        \n        if predicted_index == true_index:\n            result_status = \"✅ DOĞRU\"\n        else:\n            result_status = \"❌ YANLIŞ\"\n\n        title = f\"{result_status} | Tahmin: {predicted_label.upper()} | Gerçek: {true_label.upper()}\"\n        \n        print(\"-\" * 30)\n        print(f\"Görüntü {i+1} | Gerçek: {true_label}, Tahmin: {predicted_label} ({result_status})\")\n        display_gradcam(img_array, heatmap, title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T20:19:04.808095Z","iopub.execute_input":"2025-09-25T20:19:04.808620Z","iopub.status.idle":"2025-09-25T20:19:08.069979Z","shell.execute_reply.started":"2025-09-25T20:19:04.808595Z","shell.execute_reply":"2025-09-25T20:19:08.069317Z"}},"outputs":[],"execution_count":null}]}